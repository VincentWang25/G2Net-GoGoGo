{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b057b8e8",
   "metadata": {
    "id": "_bgvM6ea1sSE"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f79878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import OUTPUT_PATH, INPUT_PATH, DATA_PATH, MODEL_PATH\n",
    "from src.utils import prepare_args_test as prepare_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76feb55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config= Namespace(batch_size=32, batch_size_infer=4, bins=64, config='default_run', debug=True, efficientnet_size=3, epochs=20, fmax=None, fmin=22, folds=[0, 1, 2, 3, 4], hop_length=32, image_size=512, logging=True, lr=0.0001, mixed=True, model_name='Eff-B3', nfold=5, norm=1, octave=12, scale=1, seed=2021, submit=False, tfhub_model=None, tta=True, use_pseudo=True, weight='imagenet', window_type='nuttall')\n"
     ]
    }
   ],
   "source": [
    "config = prepare_args()\n",
    "print ('config=', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e67832d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d1b8c5",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1633245533461,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "I6hHnIrtyj-2"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME= config.model_name\n",
    "\n",
    "# CQT params\n",
    "FMIN=config.fmin\n",
    "FMAX=config.fmax\n",
    "WINDOW_TYPE=config.window_type\n",
    "BINS=config.bins\n",
    "HOP_LENGTH = config.hop_length\n",
    "SCALE=config.scale\n",
    "NORM=config.norm\n",
    "OCTAVE=config.octave\n",
    "\n",
    "SMOOTHING=0.00\n",
    "ST=int(4096 / 16 * 7)\n",
    "EN=int(4096 / 16 * 15)\n",
    "\n",
    "NUM_FOLDS = config.nfold\n",
    "FOLDS=config.folds\n",
    "\n",
    "LR=config.lr\n",
    "IMAGE_SIZE = config.image_size\n",
    "BATCH_SIZE = config.batch_size_infer\n",
    "EFFICIENTNET_SIZE = config.efficientnet_size\n",
    "WEIGHTS =  config.weight\n",
    "\n",
    "MIXED=True # mixed precision does not work with tf models\n",
    "TFHUB_MODEL=config.tfhub_model\n",
    "\n",
    "MIXUP_PROB = 0.0\n",
    "EPOCHS = config.epochs\n",
    "R_ANGLE = 0\n",
    "S_SHIFT = 0.0\n",
    "T_SHIFT = 0.0\n",
    "LABEL_POSITIVE_SHIFT = 1.0\n",
    "TTA = config.tta\n",
    "\n",
    "SEED = config.seed\n",
    "\n",
    "# https://www.kaggle.com/yamsam/g2net-tf-on-the-fly-cqt-tpu-inference-path\n",
    "FILES_TEST =[\n",
    "    f'{INPUT_PATH}/test_tfrecord'\n",
    "]\n",
    "\n",
    "DEBUG=config.debug\n",
    "\n",
    "if DEBUG:\n",
    "    TTA=False\n",
    "    FOLDS=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6b1b3a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3405,
     "status": "ok",
     "timestamp": 1633245540490,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "47614e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet tensorflow_addons > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e46cc7",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633245547106,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "5930c28a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 03:27:01.457538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-07 03:27:02.778314: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-07 03:27:02.778802: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-07 03:27:02.779543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-07 03:27:02.815421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:02.815968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-10-07 03:27:02.816005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-07 03:27:02.818051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-07 03:27:02.818093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-07 03:27:02.818905: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-07 03:27:02.819099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-07 03:27:02.820998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-07 03:27:02.821438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-07 03:27:02.821599: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-07 03:27:02.821769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:02.822330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:02.822790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-10-07 03:27:02.822838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-07 03:27:03.277482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-07 03:27:03.277533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-10-07 03:27:03.277541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-10-07 03:27:03.277861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.278454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.278983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.279442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9466 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "#from kaggle_datasets import KaggleDatasets\n",
    "from scipy.signal import get_window\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278dd20e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1633245547107,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "e91524c8",
    "outputId": "e63354ff-edca-4421-b8d9-68925bd64c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print('tf:',tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617bb6df",
   "metadata": {
    "id": "c70bc2a1"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d0e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd65f5b7",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1633245547107,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "53835b0d"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b53471",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1633245547108,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "a73e2541"
   },
   "outputs": [],
   "source": [
    "def auto_select_accelerator():\n",
    "    TPU_DETECTED = False\n",
    "    try:\n",
    "        if MIXED and TFHUB_MODEL is None:\n",
    "          tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "          tf.config.experimental_connect_to_cluster(tpu)\n",
    "          tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "          strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "          policy = mixed_precision.Policy('mixed_bfloat16')\n",
    "          mixed_precision.set_global_policy(policy)\n",
    "          tf.config.optimizer.set_jit(True)\n",
    "        else:\n",
    "          tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "          tf.config.experimental_connect_to_cluster(tpu)\n",
    "          tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "          strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "        TPU_DETECTED = True\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "\n",
    "    return strategy, TPU_DETECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd94dc52",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11647,
     "status": "ok",
     "timestamp": 1633245558743,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "1871c557",
    "outputId": "13a031ad-4bea-43b9-ae7c-ced7a2f3b3e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replicas\n"
     ]
    }
   ],
   "source": [
    "strategy, tpu_detected = auto_select_accelerator()\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20749399",
   "metadata": {
    "id": "57dd2278"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc76a87e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1633245558744,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "99de507f",
    "outputId": "0b139af3-89d0-426d-8a16-ebfbfa475dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaggle/G2net/input/g2net-gravitational-wave-detection/test_tfrecord\n"
     ]
    }
   ],
   "source": [
    "gcs_paths = []\n",
    "for file in FILES_TEST:\n",
    "    gcs_paths.append(file)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d64ff15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1633245559212,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "f5da9d2c",
    "outputId": "9fc2648b-83ba-4569-badd-eb6250711e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_files:  10\n"
     ]
    }
   ],
   "source": [
    "all_files = []\n",
    "\n",
    "for path in gcs_paths:\n",
    "    all_files.extend(np.sort(np.array(tf.io.gfile.glob(path + f\"/*.tfrecords\"))))\n",
    "\n",
    "print('test_files: ', len(all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b20968",
   "metadata": {
    "id": "6b64040d"
   },
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "Here's the main contribution of this notebook - Tensorflow version of on-the-fly CQT computation. Note that some of the operations used in CQT computation are not supported by TPU, therefore the implementation is not a TF layer but a function that runs on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8370115",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1633245559212,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "f909e45a"
   },
   "outputs": [],
   "source": [
    "def create_cqt_kernels(\n",
    "    q: float,\n",
    "    fs: float,\n",
    "    fmin: float,\n",
    "    n_bins: int = 84,\n",
    "    bins_per_octave: int = 12,\n",
    "    norm: float = 1,\n",
    "    window: str = \"hann\",\n",
    "    fmax: Optional[float] = None,\n",
    "    topbin_check: bool = True\n",
    ") -> Tuple[np.ndarray, int, np.ndarray, float]:\n",
    "    fft_len = 2 ** _nextpow2(np.ceil(q * fs / fmin))\n",
    "    \n",
    "    if (fmax is not None) and (n_bins is None):\n",
    "        n_bins = np.ceil(bins_per_octave * np.log2(fmax / fmin))\n",
    "        freqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n",
    "    elif (fmax is None) and (n_bins is not None):\n",
    "        freqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n",
    "    else:\n",
    "        warnings.warn(\"If nmax is given, n_bins will be ignored\", SyntaxWarning)\n",
    "        n_bins = np.ceil(bins_per_octave * np.log2(fmax / fmin))\n",
    "        freqs = fmin * 2.0 ** (np.r_[0:n_bins] / np.float(bins_per_octave))\n",
    "        \n",
    "    if np.max(freqs) > fs / 2 and topbin_check:\n",
    "        raise ValueError(f\"The top bin {np.max(freqs)} Hz has exceeded the Nyquist frequency, \\\n",
    "                           please reduce the `n_bins`\")\n",
    "    \n",
    "    kernel = np.zeros((int(n_bins), int(fft_len)), dtype=np.complex64)\n",
    "    \n",
    "    length = np.ceil(q * fs / freqs)\n",
    "    for k in range(0, int(n_bins)):\n",
    "        freq = freqs[k]\n",
    "        l = np.ceil(q * fs / freq)\n",
    "        \n",
    "        if l % 2 == 1:\n",
    "            start = int(np.ceil(fft_len / 2.0 - l / 2.0)) - 1\n",
    "        else:\n",
    "            start = int(np.ceil(fft_len / 2.0 - l / 2.0))\n",
    "\n",
    "        sig = get_window(window, int(l), fftbins=True) * np.exp(\n",
    "            np.r_[-l // 2:l // 2] * 1j * 2 * np.pi * freq / fs) / l\n",
    "        \n",
    "        if norm:\n",
    "            kernel[k, start:start + int(l)] = sig / np.linalg.norm(sig, norm)\n",
    "        else:\n",
    "            kernel[k, start:start + int(l)] = sig\n",
    "    return kernel, fft_len, length, freqs\n",
    "\n",
    "\n",
    "def _nextpow2(a: float) -> int:\n",
    "    return int(np.ceil(np.log2(a)))\n",
    "\n",
    "\n",
    "def prepare_cqt_kernel(\n",
    "    sr=22050,\n",
    "    hop_length=512,\n",
    "    fmin=32.70,\n",
    "    fmax=None,\n",
    "    n_bins=84,\n",
    "    bins_per_octave=12,\n",
    "    norm=1,\n",
    "    filter_scale=1,\n",
    "    window=\"hann\"\n",
    "):\n",
    "    q = float(filter_scale) / (2 ** (1 / bins_per_octave) - 1)\n",
    "    print(q)\n",
    "    return create_cqt_kernels(q, sr, fmin, n_bins, bins_per_octave, norm, window, fmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f83d2ffc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1633245559212,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "0ab66746",
    "outputId": "b52b6f75-3123-4709-c8b5-73dc651f12ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.817153745105756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 03:27:03.349553: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-07 03:27:03.349831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.350498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-10-07 03:27:03.350574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-07 03:27:03.350603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-07 03:27:03.350622: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-07 03:27:03.350641: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-07 03:27:03.350660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-07 03:27:03.350678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-07 03:27:03.350696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-07 03:27:03.350714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-07 03:27:03.350784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.351260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.351749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-10-07 03:27:03.351954: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-07 03:27:03.352042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.352473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-10-07 03:27:03.352500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-07 03:27:03.352520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-07 03:27:03.352538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-07 03:27:03.352556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-07 03:27:03.352573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-07 03:27:03.352591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-07 03:27:03.352609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-07 03:27:03.352626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-07 03:27:03.352691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.353164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.353576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-10-07 03:27:03.353605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-07 03:27:03.353611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-10-07 03:27:03.353616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-10-07 03:27:03.353708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.354181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-07 03:27:03.354601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9466 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cqt_kernels, KERNEL_WIDTH, lengths, _ = prepare_cqt_kernel(\n",
    "    sr=2048,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    fmin=FMIN,\n",
    "    fmax=FMAX,\n",
    "    n_bins=BINS,\n",
    "    norm=NORM,\n",
    "    window=WINDOW_TYPE,\n",
    "    bins_per_octave=OCTAVE,\n",
    "    filter_scale=SCALE)\n",
    "LENGTHS = tf.constant(lengths, dtype=tf.float32)\n",
    "CQT_KERNELS_REAL = tf.constant(np.swapaxes(cqt_kernels.real[:, np.newaxis, :], 0, 2))\n",
    "CQT_KERNELS_IMAG = tf.constant(np.swapaxes(cqt_kernels.imag[:, np.newaxis, :], 0, 2))\n",
    "PADDING = tf.constant([[0, 0],\n",
    "                        [KERNEL_WIDTH // 2, KERNEL_WIDTH // 2],\n",
    "                        [0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc67eda3",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1633245559213,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "da3bc9ed"
   },
   "outputs": [],
   "source": [
    "ORDER=[0,0,0]\n",
    "def create_cqt_image(wave, hop_length=16):\n",
    "    CQTs = []\n",
    "    for i in ORDER:\n",
    "        x = wave[i][ST:EN]\n",
    "        x = tf.expand_dims(tf.expand_dims(x, 0), 2)\n",
    "        x = tf.pad(x, PADDING, \"REFLECT\")\n",
    "\n",
    "        CQT_real = tf.nn.conv1d(x, CQT_KERNELS_REAL, stride=hop_length, padding=\"VALID\")\n",
    "        CQT_imag = -tf.nn.conv1d(x, CQT_KERNELS_IMAG, stride=hop_length, padding=\"VALID\")\n",
    "        CQT_real *= tf.math.sqrt(LENGTHS)\n",
    "        CQT_imag *= tf.math.sqrt(LENGTHS)\n",
    "\n",
    "        CQT = tf.math.sqrt(tf.pow(CQT_real, 2) + tf.pow(CQT_imag, 2))\n",
    "        CQTs.append(CQT[0])\n",
    "    return tf.stack(CQTs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b00e874a",
   "metadata": {
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1633245559549,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "2a575fd0"
   },
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        \"wave\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"wave_id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return prepare_image(example[\"wave\"], IMAGE_SIZE), tf.reshape(tf.cast(example[\"target\"], tf.float32), [1])\n",
    "\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_id):\n",
    "    tfrec_format = {\n",
    "        \"wave\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"wave_id\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return prepare_image(example[\"wave\"], IMAGE_SIZE), example[\"wave_id\"] if return_image_id else 0\n",
    "\n",
    "\n",
    "def count_data_items(filenames): \n",
    "    # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "def mixup(image, label, probability=0.5, aug_batch=64 * 8):\n",
    "    imgs = []\n",
    "    labs = []\n",
    "    for j in range(aug_batch):\n",
    "        p = tf.cast(tf.random.uniform([], 0, 1) <= probability, tf.float32)\n",
    "        k = tf.cast(tf.random.uniform([], 0, aug_batch), tf.int32)\n",
    "        a = tf.random.uniform([], 0, 1) * p\n",
    "\n",
    "        img1 = image[j]\n",
    "        img2 = image[k]\n",
    "        imgs.append((1 - a) * img1 + a * img2)\n",
    "        lab1 = label[j]\n",
    "        lab2 = label[k]\n",
    "        labs.append((1 - a) * lab1 + a * lab2)\n",
    "    image2 = tf.reshape(tf.stack(imgs), (aug_batch, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    label2 = tf.reshape(tf.stack(labs), (aug_batch,))\n",
    "    return image2, label2\n",
    "\n",
    "\n",
    "def time_shift(img, shift=T_SHIFT):\n",
    "    if shift > 0:\n",
    "        T = IMAGE_SIZE\n",
    "        P = tf.random.uniform([],0,1)\n",
    "        SHIFT = tf.cast(T * P, tf.int32)\n",
    "        return tf.concat([img[-SHIFT:], img[:-SHIFT]], axis=0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def rotate(img, angle=R_ANGLE):\n",
    "    if angle > 0:\n",
    "        P = tf.random.uniform([],0,1)\n",
    "        A = tf.cast(angle * P, tf.float32)\n",
    "        return tfa.image.rotate(img, A)\n",
    "    return img\n",
    "\n",
    "\n",
    "def spector_shift(img, shift=S_SHIFT):\n",
    "    if shift > 0:\n",
    "        T = IMAGE_SIZE\n",
    "        P = tf.random.uniform([],0,1)\n",
    "        SHIFT = tf.cast(T * P, tf.int32)\n",
    "        return tf.concat([img[:, -SHIFT:], img[:, :-SHIFT]], axis=1)\n",
    "    return img\n",
    "\n",
    "def img_aug_f(img):\n",
    "#    img = time_shift(img)\n",
    "#    img = spector_shift(img)\n",
    "    #img = tf.image.random_flip_left_right(img) \n",
    "#    img = tf.image.random_brightness(img, 0.2)\n",
    "#    img = AUGMENTATIONS_TRAIN(image=img)['image']\n",
    "    # img = rotate(img)\n",
    "    #print(img.shape)\n",
    "    img = swap_img(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def swap_img(img):\n",
    "   p = tf.random.uniform([],0,1)\n",
    "   if p < 0.2:\n",
    "     img = tf.stack([img[:,:,1], img[:,:,0], img[:,:,2]],axis=2)\n",
    "     return  img\n",
    "   else:\n",
    "     return img\n",
    "\n",
    "\n",
    "def imgs_aug_f(imgs, batch_size):\n",
    "    _imgs = []\n",
    "    DIM = IMAGE_SIZE\n",
    "    for j in range(batch_size):\n",
    "        _imgs.append(img_aug_f(imgs[j]))\n",
    "\n",
    "    return tf.reshape(tf.stack(_imgs),(batch_size,DIM,DIM,3))\n",
    "\n",
    "\n",
    "def label_positive_shift(labels):\n",
    "    return labels * LABEL_POSITIVE_SHIFT\n",
    "\n",
    "\n",
    "def aug_f(imgs, labels, batch_size):\n",
    "    #imgs, label = mixup(imgs, labels, MIXUP_PROB, batch_size)\n",
    "    imgs = imgs_aug_f(imgs, batch_size) \n",
    "    return imgs, labels\n",
    "\n",
    "# used for whitening\n",
    "window = tf.cast(np.load(DATA_PATH/'window.npy'), tf.float64)\n",
    "arv_w = tf.cast(np.load(DATA_PATH/'avr_w.npy'), tf.complex64)\n",
    "\n",
    "def whiten(c):\n",
    "  #print (c.shape)\n",
    "  c2 = tf.concat([tf.reverse(-c, axis=[1])[:,4096-2049:-1] + 2 *c[:,:1], c, tf.reverse(-c, axis=[1])[:,1:2049] + 2*c[:,-2:-1]],axis=1)\n",
    "  #print (c2.shape)\n",
    "  c3 = tf.math.real(tf.signal.ifft(tf.signal.fft(tf.cast(1e20*c2*window, tf.complex64))/arv_w))[:,2048:-2048]\n",
    "  #print (c3.shape)\n",
    "  return c3\n",
    "\n",
    "\n",
    "def prepare_image(wave, dim=256):\n",
    "    wave = tf.reshape(tf.io.decode_raw(wave, tf.float64), (3, 4096))\n",
    "    #wave = tf.cast(wave, tf.float32)\n",
    "    wave = whiten(wave)\n",
    "    # normalized_waves = []\n",
    "    # for i in range(3):\n",
    "    #     normalized_wave = wave[i] - means[i]\n",
    "    #     normalized_wave = normalized_wave / stds[i]\n",
    "\n",
    "    #     normalized_waves.append(normalized_wave)\n",
    "    # wave = tf.stack(normalized_waves)\n",
    "    wave = tf.cast(wave, tf.float32)\n",
    "    image = create_cqt_image(wave, HOP_LENGTH)\n",
    "    #image = tf.keras.layers.Normalization()(image)\n",
    "    image = tf.image.resize(image, size=(dim, dim))\n",
    "    return tf.reshape(image, (dim, dim, 3))\n",
    "\n",
    "\n",
    "def get_dataset(files, batch_size=16, repeat=False, shuffle=False, aug=True, labeled=True, return_image_ids=True):\n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO, compression_type=\"GZIP\")\n",
    "    ds = ds.cache()\n",
    "\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1024 * 2)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "\n",
    "    if labeled:\n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_ids), num_parallel_calls=AUTO)\n",
    "\n",
    "    ds = ds.batch(batch_size * REPLICAS)\n",
    "    if aug:\n",
    "        ds = ds.map(lambda x, y: aug_f(x, y, batch_size * REPLICAS), num_parallel_calls=AUTO)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273fb97f",
   "metadata": {
    "id": "a835683f"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad6b9d70",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1633245559550,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "4a384d21"
   },
   "outputs": [],
   "source": [
    "def build_model(size=256, efficientnet_size=0, weights=\"imagenet\", count=0):\n",
    "    inputs = tf.keras.layers.Input(shape=(size, size, 3))\n",
    "    \n",
    "    if TFHUB_MODEL:\n",
    "      load_options = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
    "      loaded_model = hub.load(TFHUB_MODEL, options=load_options)\n",
    "      efn_layer = hub.KerasLayer(loaded_model, trainable=True) \n",
    "      x = efn_layer(inputs)\n",
    "    else:\n",
    "      efn_string= f\"EfficientNetB{efficientnet_size}\"\n",
    "      efn_layer = getattr(efn, efn_string)(input_shape=(size, size, 3), weights=weights, include_top=False)\n",
    "      x = efn_layer(inputs)\n",
    "      x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    lr_decayed_fn = tf.keras.experimental.CosineDecay(1e-3, count)\n",
    "    opt = tfa.optimizers.AdamW(lr_decayed_fn, learning_rate=LR)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=SMOOTHING)\n",
    "    #loss = tfa.losses.SigmoidFocalCrossEntropy()\n",
    "\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=[\"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c377a2e1",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1633245559550,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "ec45dfe6"
   },
   "outputs": [],
   "source": [
    "def get_lr_callback(batch_size=8, replicas=8):\n",
    "    lr_start   = 1e-4\n",
    "    lr_max     = 0.000015 * replicas * batch_size\n",
    "    lr_min     = 1e-7\n",
    "    lr_ramp_ep = 3\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.7\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "            \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "            \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d9b1b58",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633245559550,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "z44mU7F9647i"
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "def display_one_flower(image, title, subplot, red=False):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    # for i in range(3):\n",
    "    #   image[i,:] -= image[i,:].min()\n",
    "    #   image[i,:] /= image[i,:].max()\n",
    "#    print (image.shape)\n",
    "    plt.imshow(image[:,:,0].transpose())\n",
    "    plt.title(title, fontsize=16, color='red' if red else 'black')\n",
    "    return subplot+1\n",
    "\n",
    "def dataset_to_numpy_util(dataset, N):\n",
    "    dataset = dataset.unbatch().batch(N)\n",
    "    for images, labels in dataset:\n",
    "        numpy_images = images.numpy()\n",
    "        numpy_labels = labels.numpy()\n",
    "        break;  \n",
    "    return numpy_images, numpy_labels\n",
    "\n",
    "def display_9_images_from_dataset(dataset):\n",
    "    subplot=331\n",
    "    plt.figure(figsize=(13,13))\n",
    "    images, labels = dataset_to_numpy_util(dataset, 9)\n",
    "    for i, image in enumerate(images):\n",
    "        title = labels[i]\n",
    "        subplot = display_one_flower(image, f'{title}', subplot)\n",
    "        if i >= 8:\n",
    "\n",
    "            break;\n",
    "              \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c4ccf",
   "metadata": {
    "id": "7df4c16c"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75551fb5",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1633245567781,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "Eg4zwG2N3IsG"
   },
   "outputs": [],
   "source": [
    "files_test_all = np.array(all_files)\n",
    "all_test_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "306cacd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug:only use 1file /home/kaggle/G2net/input/g2net-gravitational-wave-detection/test_tfrecord/test0.tfrecords\n"
     ]
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    files_test_all = files_test_all[0]\n",
    "    print('debug:only use 1file', files_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b3804fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1633245567781,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "xufuWP1K7QLC",
    "outputId": "86b236dc-cac6-4a65-d52c-d96d1577cd1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011400\n"
     ]
    }
   ],
   "source": [
    "# def count_data_items(filenames): \n",
    "#     # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "#     n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "#     return np.sum(n)\n",
    "\n",
    "# count_data_items_test = count_data_items\n",
    "\n",
    "# for arais dataset\n",
    "# def count_data_items(fileids):\n",
    "#     return len(fileids) * 5600 # 28000\n",
    "\n",
    "def count_data_items_test(fileids):\n",
    "    return len(fileids) * 22600\n",
    "\n",
    "print (count_data_items_test(files_test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cb82c23",
   "metadata": {
    "executionInfo": {
     "elapsed": 11819,
     "status": "ok",
     "timestamp": 1633245579596,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "B4LgqAAn4mke"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = build_model(\n",
    "        size=IMAGE_SIZE,\n",
    "        efficientnet_size=EFFICIENTNET_SIZE,\n",
    "        weights=WEIGHTS,\n",
    "        count=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "effd4e55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1280877,
     "status": "ok",
     "timestamp": 1633246860470,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "QL4l0VsB4pkM",
    "outputId": "eb0d345c-552e-4353-e4fa-118cbbdae5f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weight for Fold 1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-07 03:27:06.300966: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-07 03:27:06.320144: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3593145000 Hz\n",
      "2021-10-07 03:27:07.539812: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-07 03:27:08.008699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-07 03:27:08.022227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251425/251425 [==============================] - 17040s 68ms/step\n",
      "Load weight for Fold 2 model\n",
      " 30176/251425 [==>...........................] - ETA: 4:03:29"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42996/3494449615.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_test_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_image_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mSTEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_data_items_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_test_all\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mREPLICAS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcount_data_items_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_test_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mall_test_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1640\u001b[0m                   outputs, batch_outputs)\n\u001b[1;32m   1641\u001b[0m             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expect x to be a non-empty array or dataset.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_predict_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    496\u001b[0m     \"\"\"\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_predict_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ORDER=[0,1,2]\n",
    "\n",
    "for i in FOLDS:\n",
    "    print(f\"Load weight for Fold {i + 1} model\")\n",
    "    model.load_weights(f\"{MODEL_PATH}/{MODEL_NAME}/fold{i}.h5\")\n",
    "    ds_test = get_dataset(files_test_all, batch_size=BATCH_SIZE * 2, repeat=True, shuffle=False, aug=False, labeled=False, return_image_ids=False)\n",
    "    STEPS = count_data_items_test(files_test_all) / BATCH_SIZE / 2 / REPLICAS\n",
    "    pred = model.predict(ds_test, verbose=1, steps=STEPS)[:count_data_items_test(files_test_all)]\n",
    "\n",
    "    all_test_preds.append(pred.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f33d7c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e468bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1246614,
     "status": "ok",
     "timestamp": 1633248107069,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "jN4BcnCh4rxq",
    "outputId": "8a92e122-5c3b-49a5-df80-973af44c997a"
   },
   "outputs": [],
   "source": [
    "if TTA:\n",
    "    ORDER=[1,0,2]\n",
    "\n",
    "    for i in FOLDS:\n",
    "        print(f\"Load weight for Fold {i + 1} model\")\n",
    "        model.load_weights(f\"{MODEL_PATH}/{MODEL_NAME}/fold{i}.h5\")\n",
    "\n",
    "        ds_test = get_dataset(files_test_all, batch_size=BATCH_SIZE * 2, repeat=True, shuffle=False, aug=False, labeled=False, return_image_ids=False)\n",
    "        STEPS = count_data_items_test(files_test_all) / BATCH_SIZE / 2 / REPLICAS\n",
    "        pred = model.predict(ds_test, verbose=1, steps=STEPS)[:count_data_items_test(files_test_all)]\n",
    "\n",
    "        all_test_preds.append(pred.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cfa4ad",
   "metadata": {
    "executionInfo": {
     "elapsed": 445120,
     "status": "ok",
     "timestamp": 1633248552175,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "fMBt9NDi4wgI"
   },
   "outputs": [],
   "source": [
    "ds_test = get_dataset(files_test_all, batch_size=BATCH_SIZE * 2, repeat=False, shuffle=False, aug=False, labeled=False, return_image_ids=True)\n",
    "file_ids = np.array([target.numpy() for img, target in iter(ds_test.unbatch())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c0b06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1633248552176,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "5hpmd-JO4yun",
    "outputId": "a73d7061-983c-4f30-cd7f-df321920fdef"
   },
   "outputs": [],
   "source": [
    "test_pred = np.zeros_like(all_test_preds[0])\n",
    "for i in range(len(all_test_preds)):\n",
    "    test_pred += all_test_preds[i] / len(all_test_preds)\n",
    "    \n",
    "test_df = pd.DataFrame({\n",
    "    \"id\": [i.decode(\"UTF-8\") for i in file_ids],\n",
    "    \"target\": test_pred.astype(float)\n",
    "})\n",
    "\n",
    "#test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b673c",
   "metadata": {
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1633248553193,
     "user": {
      "displayName": "136 yamashitan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17856296841449186565"
     },
     "user_tz": -540
    },
    "id": "aov0g26e403m"
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(f\"{OUTPUT_PATH}/{MODEL_NAME}/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "inference_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-19T11:19:39.156011",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
